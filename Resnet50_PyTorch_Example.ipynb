{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Resnet50_PyTorch_Example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HackBinghamton/GoogleColabSample/blob/master/Resnet50_PyTorch_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIolfEVCHh7j",
        "colab_type": "text"
      },
      "source": [
        "# HackBU Workshop Template\n",
        "\n",
        "<img src=\"https://github.com/HackBinghamton/GoogleColabSample/blob/master/assets/hackbu.png?raw=1\" height=20% width=20% align=\"left\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqVbDXK8Hh7m",
        "colab_type": "text"
      },
      "source": [
        "HackBU Workshop Description."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAr4cnt4Hh7o",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpGRH3-LHh7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone into our git repo\n",
        "!git clone https://github.com/HackBinghamton/GoogleColabSample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzApf_TcHh7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Move into our git repo\n",
        "%cd GoogleColabSample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3SxtYHxHh7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed_VHD2VHh71",
        "colab_type": "text"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo930woUHh72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://pytorch.org/docs/stable/torchvision/models.html\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "model = models.resnet50(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I22IBpCQHh75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms\n",
        "# 1. Resize any input image to be 256x256\n",
        "# 2. Crop the center 224x224 of the image to match expected input size\n",
        "# 3. Convert image to a PyTorch Tensor for computation\n",
        "# 4. Normalize the image/tensor to match expected input values\n",
        "preprocess = transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225]),\n",
        "        ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHKsiLlvHh79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "img = Image.open(\"assets/dog.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRMBAgwvHh8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display # to display images\n",
        "display(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1Ep7aXjHh8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add extra first dimension for batch size\n",
        "prep_img = preprocess(img).unsqueeze(0)\n",
        "print(\"Input shape:\", prep_img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj_vW7zyHh8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup model for making predictions\n",
        "model.eval()\n",
        "# Make prediction on input image\n",
        "preds = model(prep_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4uYP33KHh8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get output labels to see model prediction\n",
        "with open(\"assets/imagenet_classes.txt\", 'r') as f:\n",
        "    labels = [line.strip() for line in f.readlines()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OTKjE-OHh8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get index of prediction with the highest value\n",
        "_, idx = torch.max(preds, 1)\n",
        "# Map output index to our english labels\n",
        "print(\"Prediction:\", labels[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}